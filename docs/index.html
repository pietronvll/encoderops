<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems</title>
    <meta name="description" content="Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">

    <meta content="Website Template for AI Research" property="og:description">

    <meta name="twitter:description" content="Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems">
    
    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.7.2-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script>  <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background: linear-gradient(0deg, #fffded 0%,  #e3ffe7 100%)">
        <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
        <div class="blog-title no-cover">
            <div class="blog-intro">
                <div>
                    <h1 class="title">Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems</h1>
                    <p class="author">
                        Giacomo Turri <sup>1</sup>, Luigi Bonati <sup>1</sup>, Kai Zhu<sup>2</sup>, Massimiliano Pontil<sup>1,3</sup>, and Pietro Novelli<sup>1</sup>
                    </p>
                    <p class="author" style="padding-top: 0px;">
                        <sup>1</sup> Istituto Italiano di Tecnologia <br>
                        <sup>2</sup> Zhejiang University <br>
                        <sup>3</sup> AI Centre, University College London
                    </p>
                    <p class="abstract">
                        We introduce an encoder-only approach to learn the evolution operators of large-scale non-linear dynamical systems, such as those describing complex natural phenomena. Evolution operators are particularly well-suited for analyzing systems that exhibit complex spatio-temporal patterns and have become a key analytical tool across various scientific communities. As terabyte-scale weather datasets and simulation tools capable of running millions of molecular dynamics steps per day are becoming commodities, our approach provides an effective tool to make sense of them from a data-driven perspective. The core of it lies in a remarkable connection between self-supervised representation learning methods and the recently established learning theory of evolution operators.
                    <!-- Using FontAwesome Free -->
                    <div class="info">
                        <div>
                            <a href="https://arxiv.org" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)"> Paper <i class="fa-solid fa-book-open"></i></a> &nbsp;&nbsp; 
                            <a href="https://github.com/pietronvll/encoderops" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Code <i class="fa-solid fa-code"></i></a>  &nbsp;&nbsp; 
                            <a href="https://huggingface.co/datasets/pnovelli/encoderops/tree/main/" class="button icon" style="background-color: rgba(255, 255, 255, 0.2);">Data <i class="fa-solid fa-database"></i></i></a> &nbsp;&nbsp; 
                            <a href="https://huggingface.co/pnovelli/encoderops/tree/main/" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Models <i class="fa-solid fa-square-binary"></i></a> 
                        </div>
                    </div>
                </div>
               
                <!-- <div class="info">
                    <p>CVPR 2048 / Best Paper Award</p>
                </div> -->
            </div>
            <!-- <div class="blog-cover">
                <img class="foreground" src="assets/figures/clarity.png">
                <img class="background" src="assets/figures/clarity.png">
            </div> -->
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1 >
            Introduction
        </h1>
        <p class='text'>
            Dynamical systems are crucial for understanding phenomena across various scientific disciplines, from physics and biology to climate science. Traditionally, these systems are modeled using differential equations derived from first principles. However, as systems grow in scale and complexity, this approach quickly becomes computationally intractable and difficult to interpret, hindering the study of large-scale phenomena. Simultaneously, advancements in data collection techniques and computational power lead to an explosion of available data from experiments and high-fidelity simulations. This abundance of data makes data-driven approaches increasingly appealing for studying complex dynamics, with machine learning becoming a dominant paradigm. While many data-driven methods excel at prediction, there remains a significant gap in approaches that offer interpretability, which is paramount for understanding why a system evolves in a certain way. This work introduces an encoder-only approach to learn evolution operators of large-linear dynamical systems, bridging self-supervised representation learning with the theory of evolution operators to provide interpretable insights into complex natural phenomena.
        </p>
    </div>


    <div class="container blog main">
        <h1>Results</h1>
        <p class="text">
            Our method proposes an encoder-only approach for learning evolution operators that is based on self-supervised contrastive learning and scales effectively to large dynamical systems. This approach reveals a deep connection between evolution operator learning and contrastive self-supervised representation learning schemes. The core idea is to optimize a model for the density ratio using a bilinear form $\langle\varphi(x_{t}),P\varphi(x_{t+1})\rangle$, where $\varphi$ is a d-dimensional encoder and P is a linear predictor layer that approximates the action of the evolution operator E. Unlike traditional encoder-decoder schemes that minimize reconstruction errors and can be twice as large, our encoder-only method prioritizes approximating the spectral decomposition of E over raw forecasting performances, as the main advantages of evolution operators stem from their spectral decomposition. The loss function directly optimizes the $L^{2}$ error between the density ratio and our bilinear model, matching the negative VAMP-2 score when the predictor is optimal. Crucially, our approach avoids computationally unwieldy and unstable matrix inversions in the loss computation, which are common in other methods, instead relying on simple matrix multiplications that are efficient for GPU-based training. This makes the method broadly applicable, especially for interpretability and model reduction in scientific dynamical systems.

        </p>
    </div>



    <div class="container blog main">
        <h1>Applications</h1>
        <h2>Protein folding dynamics</h2>
        <p class="text">
            The Trp-Cage miniprotein, a widely studied benchmark for protein folding, is analyzed using our approach with a high-resolution molecular representation of all 144 heavy atoms, employing a SchNet graph neural network as the encoder. The leading eigenfunction $\Psi_{1}(x)=\langle q_{1},\varphi(x)\rangle$ strongly correlates with the system's root-mean-square deviation (RMSD) from the folded structure, confirming that $\Psi_{1}$ encodes the folding-to-unfolding transition. Clustering the molecular configurations according to the values of $\Psi_{1}$ clearly separates folded and unfolded ensembles. Analysis through a sparse LASSO model reveals a network of hydrogen bonds stabilizing the folded state, including contributions from side-chain interactions that previous coarse-grained models miss. The implied timescale $\tau_{1}$ derived from the leading eigenvalue of the learned operator is approximately $2.5~\mu s$, which is higher than the $2~\mu s$ timescale obtained by other methods, suggesting a better approximation of the true slow dynamics.

        </p>
    </div>
    <div class="container blog main">
        <img src="clarity/images/trpcage.png">
    </div>

    <div class="container blog main">

        <h2>Ligand binding dynamics</h2>
        <p class="text">
            Our method applies to ligand binding dynamics, specifically involving Calixarene host-guest systems. The eigenfunctions $\Psi_{1}$ and $\Psi_{2}$ effectively capture ligand transitions between unbound, semi-bound, and bound states. The model learns these dynamics both from scratch and by transferring representations from other ligands, with the latter closely matching the former. This demonstrates the method's capability to provide insights into complex molecular interaction processes.

        </p>
    </div>
    <div class="container blog main">
        <img src="clarity/images/calixarene.png">
    </div>
    <div class="container blog main">
        <h2>Climate Patterns</h2>
        <p class="text">
            In our experiment on climate patterns, we apply our method to analyze the El Niño-Southern Oscillation (ENSO), a major driver of global climate variability. Our approach aims to identify and characterize the spatio-temporal patterns associated with ENSO events. The leading eigenfunctions of the learned evolution operator are highly correlated to ENSO phenomenon. This application demonstrates the potential of our framework for extracting meaningful and interpretable patterns from high-dimensional climate data, offering a data-driven perspective to understanding complex Earth system dynamics.
        </p>
    </div>
    <div class="container blog main">
        <img src="clarity/images/ENSO.png">
    </div>


    <div class="container blog main">
        <h1>Citation</h1>
<pre><code class="plaintext">@article{turri2025self,
    title={Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems},
    author={Turri Giacomo, Bonati Luigi, Zhu Kai, Pontil Massimiliano, Novelli Pietro},
    year={2025}
}</code></pre>
    </div>

    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>    
    </footer>
    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>
