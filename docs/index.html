<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems</title>
    <meta name="description" content="Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">

    <meta content="Website Template for AI Research" property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description" content="Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems">
    
    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.7.2-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script>  <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background: linear-gradient(90deg, hsla(298, 68%, 90%, 1) 0%, hsla(30, 82%, 91%, 1) 100%);">
        <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
        <div class="blog-title no-cover">
            <div class="blog-intro">
                <div>
                    <h1 class="title">Self-Supervised Evolution Operator Learning for High-Dimensional Dynamical Systems</h1>
                    <p class="author">
                        Giacomo Turri <sup>1</sup>, Luigi Bonati <sup>1</sup>, Kai Zhu<sup>2</sup>, Massimiliano Pontil<sup>1,3</sup>, and Pietro Novelli<sup>1</sup>
                    </p>
                    <p class="author" style="padding-top: 0px;">
                        <sup>1</sup> Istituto Italiano di Tecnologia <br>
                        <sup>2</sup> Zhejiang University <br>
                        <sup>3</sup> AI Centre, University College London
                    </p>
                    <p class="abstract">
                        We introduce an encoder-only approach to learn the evolution operators of large-scale non-linear dynamical systems, such as those describing complex natural phenomena. Evolution operators are particularly well-suited for analyzing systems that exhibit complex spatio-temporal patterns and have become a key analytical tool across various scientific communities. As terabyte-scale weather datasets and simulation tools capable of running millions of molecular dynamics steps per day are becoming commodities, our approach provides an effective tool to make sense of them from a data-driven perspective. The core of it lies in a remarkable connection between self-supervised representation learning methods and the recently established learning theory of evolution operators.
                    <!-- Using FontAwesome Free -->
                    <div class="info">
                        <div>
                            <a href="https://arxiv.org" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)"> Paper <i class="fa-solid fa-book-open"></i></a> &nbsp;&nbsp; 
                            <a href="https://github.com/pietronvll/encoderops" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Code <i class="fa-solid fa-code"></i></a>  &nbsp;&nbsp; 
                            <a href="https://huggingface.co/datasets/pnovelli/encoderops/tree/main/" class="button icon" style="background-color: rgba(255, 255, 255, 0.2);">Data <i class="fa-solid fa-database"></i></i></a> &nbsp;&nbsp; 
                            <a href="https://huggingface.co/pnovelli/encoderops/tree/main/" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Models <i class="fa-solid fa-square-binary"></i></a> 
                        </div>
                    </div>
                </div>
               
                <!-- <div class="info">
                    <p>CVPR 2048 / Best Paper Award</p>
                </div> -->
            </div>
            <!-- <div class="blog-cover">
                <img class="foreground" src="assets/figures/clarity.png">
                <img class="background" src="assets/figures/clarity.png">
            </div> -->
        </div>
    </div>


    <div class="container blog main first" id="blog-main">
        <h1 >
            Introduction
        </h1>
        <p class='text'>
            Dynamical systems are crucial for understanding phenomena across various scientific disciplines, from physics and biology to climate science. Traditionally, these systems were modeled using differential equations derived from first principles. However, as systems become larger and more complex, this approach can become computationally intractable and difficult to interpret. The recent explosion of data from experiments and high-fidelity simulations makes data-driven methods, particularly machine learning, increasingly appealing for studying complex dynamics. While many data-driven methods excel at prediction, there is a significant need for approaches that offer interpretability, which is paramount for understanding why a system evolves in a certain way. This work introduces an encoder-only approach to learn evolution operators of large-scale non-linear dynamical systems, bridging self-supervised representation learning with the theory of evolution operators to provide interpretable insights into complex natural phenomena.
        </p>
    </div>


    <div class="container blog main">
        <h1>Results</h1>
        <p class="text">
            Arcu imperdiet nunc, dignissim ornare arcu nam eros cras venenatis. Non volutpat parturient luctus eros litora natoque; elementum dui. Nulla cubilia et nascetur dictum nisi phasellus. Natoque himenaeos porta vulputate interdum id mollis. Fames diam integer semper ligula per. Sapien ex magnis pellentesque neque rhoncus conubia. Purus torquent nunc ligula auctor cras pharetra. Porttitor vulputate dis ante suspendisse a iaculis massa sagittis.
        </p>
    </div>



    <div class="container blog main">
        <h1>Applications</h1>
        <h2>Protein folding dynamics</h2>
        <p class="text">
            The Trp-Cage miniprotein, a benchmark for protein folding, was studied using our approach with a high-resolution molecular representation of all 144 heavy atoms, employing a SchNet graph neural network as the encoder. The leading eigenfunction, $\Psi_1(x)$, strongly correlated with the system's root-mean-square deviation (RMSD) from the folded structure, indicating its ability to encode the folding-to-unfolding transition. Clustering configurations based on $\Psi_1$ values clearly separated folded and unfolded ensembles. Analysis through a sparse LASSO model revealed a network of hydrogen bonds stabilizing the folded state, including side-chain interactions that previous coarse-grained models missed. The implied timescale $\tau_1$ derived from the leading eigenvalue was approximately $2.5 \mu s$, higher than that obtained by other methods, suggesting a better approximation of the true slow dynamics
        </p>
    </div>
    <div class="container blog main">
        <img src="clarity/images/trpcage.png">
    </div>

    <div class="container blog main">

        <h2>Ligand binding dynamics</h2>
        <p class="text">
            Lorem ipsum odor amet, consectetuer adipiscing elit. Himenaeos sociosqu facilisi ante; cubilia sociosqu magna libero. Dignissim vehicula felis taciti sollicitudin quam ligula a, vivamus porta. Tellus facilisi pharetra non posuere a sapien. Sagittis felis lectus ac interdum pretium sit himenaeos.
        </p>
    </div>
    <div class="container blog main">
        <img src="clarity/images/calixarene.png">
    </div>
    <div class="container blog main">
        <h2>Climate Patterns</h2>
        <p class="text">
            Lorem ipsum odor amet, consectetuer adipiscing elit. Himenaeos sociosqu facilisi ante; cubilia sociosqu magna libero. Dignissim vehicula felis taciti sollicitudin quam ligula a, vivamus porta. Tellus facilisi pharetra non posuere a sapien. Sagittis felis lectus ac interdum pretium sit himenaeos.
        </p>
    </div>
    <div class="container blog main">
        <img src="clarity/images/ENSO.png">
    </div>


    <div class="container blog main">
        <h1>Conclusion</h1>
        <p class="text">
            Per aptent diam; ut in mauris ultricies torquent conubia dolor. Aliquet venenatis sapien, dictum finibus ad dui. Finibus sollicitudin nullam consectetur malesuada molestie semper dolor. Platea eget hac cursus aptent maecenas penatibus vulputate. Ligula libero torquent sit per praesent praesent. Sodales risus mattis enim odio risus tristique. Dapibus vivamus quis scelerisque sollicitudin penatibus placerat erat. Ante aliquet vel; morbi quisque leo morbi. Ac sollicitudin imperdiet lacus integer cursus metus parturient euismod sociosqu.
        </p>
    </div>

    <div class="container blog main">
        <h1>Citation</h1>
        <p class="text">
            Dictumst eu himenaeos malesuada nisi eros auctor id suspendisse. Ipsum parturient est vitae proin maecenas. Nulla mollis vivamus cras nam dapibus consectetur. Id efficitur ac ultricies ornare at litora. Vestibulum nibh cursus eu gravida vivamus sem vulputate. Montes nisi ipsum urna vitae semper suscipit.
        </p>
<pre><code class="plaintext">@article{doe2048agi,
    title={Artificial General Intelligence},
    author={Doe John},
    journal={nature},
    year={2048}
}</code></pre>
    </div>

    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>    
    </footer>
    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>
